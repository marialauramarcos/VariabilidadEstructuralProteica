#
#    - family: The family of the protein to mutate. It can be "globins", "serinProteases",
#    "snakesToxin", "sh3", "fabp", "rrm", "phoslip" or "cys".
#    - p.ref: The pdb code (pdbid) of the protein to mutate (example: "1a6m"). The protein must be a member of
#    the selected family. This pdbid must not be included in the dataset ("DATA/family_dataset.csv").
#    - chain.p.ref: The chain of p.ref in the pdb file obtained from Homstrad.
#    - n.mut.p: The number of mutants to generate for each member of the family. For example, if the family has 20
#    members, the program generates n.mut.p x 20 mutants.
#    - fmax: Argument for "LFENM". It is the maximun value for the forces that model the mutations.
#    - R0: the Cut-off for the "ANM" (Anisotropic Network Model) that represents the proteins.
#    - rotate: It can be "TRUE" or "FALSE". If it is "TRUE", r.p.2 is rotated in order to minimize RMSD with r.p.ref.
#    - heme: Argument for "globins". It can be "TRUE" or "FALSE". If it is "TRUE", the program considers the heme group.
#    - calculate.betas: It can be "TRUE" or "FALSE". If it is "TRUE", the program calculates betas of the "Stress Model".
#    - analyze.family: It can be "TRUE" or "FALSE". If it is "TRUE", the program analyzes the family.
#    - generate.mutants: It can be "TRUE" or "FALSE". If it is "TRUE", the program generates new mutants.
#    - K.analysis: It can be "K" or "Keff". For "K" or "Keff", the analysis is based on normal modes of "K" or "Keff"
#    respectibly.
# Remove objects.
rm(list = ls())
# Load packages.
library(bio3d)
library(seqinr)
# Data dir.
data.dir <- "DATA"
# Output dir.
out.dir <- "OUT"
# General parameters.
TOLERANCE = 1e-10
# Functions filenames.
AnalyzeExperimentalTheoretical.fname <- "FUNCTIONS/AnalyzeExperimentalTheoretical.R"
AnalyzeFamily.fname <- "FUNCTIONS/AnalyzeFamily.R"
AnalyzeAlignment.fname <- "FUNCTIONS/AnalyzeAlignment.R"
GenerateMutants.fname <- "FUNCTIONS/GenerateMutants.R"
ReadFasta.fname <- "FUNCTIONS/ReadFasta.R"
ReadCA.fname <- "FUNCTIONS/ReadCA.R"
ReadHeme.fname <- "FUNCTIONS/ReadHeme.R"
CalculateBetas.fname <- "FUNCTIONS/CalculateBetas.R"
CalculateENMKeff.fname <- "FUNCTIONS/CalculateENMKeff.R"
CalculateENMK.fname <- "FUNCTIONS/CalculateENMK.R"
CalculateKij.fname <- "FUNCTIONS/CalculateKij.R"
CalculateForce.fname <- "FUNCTIONS/CalculateForce.R"
CalculateVariability.fname <- "FUNCTIONS/CalculateVariability.R"
# Source functions.
source(AnalyzeExperimentalTheoretical.fname)
source(AnalyzeFamily.fname)
source(AnalyzeAlignment.fname)
source(GenerateMutants.fname)
source(ReadFasta.fname)
source(ReadCA.fname)
source(ReadHeme.fname)
source(CalculateBetas.fname)
source(CalculateENMKeff.fname)
source(CalculateENMK.fname)
source(CalculateKij.fname)
source(CalculateForce.fname)
source(CalculateVariability.fname)
# Read input.
input.fname <- file.path("input_MainProgram.csv")
input <- read.csv(input.fname)
# Start a loop to analyze each family.
for (a in (1:nrow(input))) {
family <- as.character(input$family)[a]
print(family)
p.ref <- as.character(input$p.ref)[a]
chain.p.ref <- as.character(input$chain.p.ref)[a]
n.mut.p = input$n.mut.p[a]
fmax = input$fmax[a]
R0 = input$R0[a]
rotate <- input$rotate[a]
heme <- input$heme[a]
calculate.betas <- input$calculate.betas[a]
analyze.family <- input$analyze.family[a]
generate.mutants <- input$generate.mutants[a]
analyze.experimental.theoretical <- input$analyze.experimental.theoretical[a]
K.analysis <- input$K.analysis[a]
# Analyze the alignment of the family.
if (analyze.family == "TRUE") {
AnalyzeFamily(family,
p.ref,
data.dir,
out.dir)
}
# Generate id for betas output filename.
betas.fname.id <- paste(family, "_", p.ref, "_R0_", R0, sep = "")
# Calculate betas for the "Stress Model".
if (calculate.betas == "TRUE") {
CalculateBetas(chain.p.ref,
fmax,
R0,
heme,
data.dir,
out.dir,
betas.fname.id,
TOLERANCE)
}
# Read betas.
all.betas <- read.csv(file.path(out.dir, paste(betas.fname.id, "_out_all.betas.csv", sep = "")))
regimens <- list("strong.sel", "medium.sel", "weak.sel", "no.sel")
# Start a loop for each beta.
for (beta in all.betas)  {
# Generate ids for output filenames.
mut.fname.id <- paste(family, "_R0_", R0, "_beta_", regimens[all.betas == beta], sep = "")
analysis.fname.id <- paste(mut.fname.id, "_K.analysis_", K.analysis, sep = "")
# Generate mutants.
if (generate.mutants == "TRUE") {
GenerateMutants(family,
chain.p.ref,
n.mut.p,
fmax,
R0,
beta,
heme,
data.dir,
out.dir,
mut.fname.id,
TOLERANCE)
}
# Analyze measures of variability of experimental proteins and simulated mutants.
if (analyze.experimental.theoretical == "TRUE") {
AnalyzeExperimentalTheoretical(family,
chain.p.ref,
n.mut.p,
R0,
rotate,
heme,
K.analysis,
data.dir,
out.dir,
mut.fname.id,
analysis.fname.id,
TOLERANCE)
}
}
}
# Load packages.
library(knitr)
library(markdown)
# Read input.
input.fname <- file.path("input_MainMultipleReport.csv")
input <- read.csv(input.fname)
# Satart a loop for each family.
for (a in (1:nrow(input))) {
print(a)
family <- as.character(input$family)[a]
p.ref <- as.character(input$p.ref)[a]
chain.p.ref = input$chain.p.ref[a]
n.mut.p = input$n.mut.p[a]
R0 = input$R0[a]
K.analysis = input$K.analysis[a]
# Generate a report.
rmarkdown::render('MultipleReportAllBetas.Rmd',
output_file =  paste("report_", family, "_R0_", R0, "_K.analysis_", K.analysis, ".html", sep = ''))
}
# Load packages.
library(knitr)
library(markdown)
# Read input.
input.fname <- file.path("input_MainMultipleReport.csv")
input <- read.csv(input.fname)
# Satart a loop for each family.
for (a in (1:nrow(input))) {
print(a)
family <- as.character(input$family)[a]
p.ref <- as.character(input$p.ref)[a]
chain.p.ref = input$chain.p.ref[a]
n.mut.p = input$n.mut.p[a]
R0 = input$R0[a]
K.analysis = input$K.analysis[a]
# Generate a report.
rmarkdown::render('MultipleReportAllBetas.Rmd',
output_file =  paste("report_", family, "_R0_", R0, "_K.analysis_", K.analysis, ".html", sep = ''))
}
# Load packages.
library(knitr)
library(markdown)
# Read input.
input.fname <- file.path("input_MainMultipleReport.csv")
input <- read.csv(input.fname)
# Satart a loop for each family.
for (a in (1:nrow(input))) {
print(a)
family <- as.character(input$family)[a]
p.ref <- as.character(input$p.ref)[a]
chain.p.ref = input$chain.p.ref[a]
n.mut.p = input$n.mut.p[a]
R0 = input$R0[a]
K.analysis = input$K.analysis[a]
# Generate a report.
rmarkdown::render('MultipleReportAllBetas.Rmd',
output_file =  paste("report_", family, "_R0_", R0, "_K.analysis_", K.analysis, ".html", sep = ''))
}
family
# Chunk 1: setup
knitr::opts_chunk$set(warning = FALSE, echo = FALSE, message = FALSE)
# Chunk 2
# Load packages.
library(bio3d)
# Source functions.
source("FUNCTIONS/CalculateGroupsMeansQuantiles.R")
# Set directories.
data.dir <- "DATA"
out.dir <- "OUT"
# p.ref.
n.sites.p.ref = read.csv(file.path(out.dir, paste(family, "_out_m.n.sites.p.ref.csv", sep = "")))$V1[1]
# Create matrices to save data.
m.MSDi.fit = matrix(nrow = 4, ncol = n.sites.p.ref)
m.exp.MSDi = matrix(nrow = 4, ncol = n.sites.p.ref)
m.exp.MSDi.sd = matrix(nrow = 4, ncol = n.sites.p.ref)
m.MSDi.R2 = matrix(nrow = 4, ncol = 1)
m.MSDi.MSE = matrix(nrow = 4, ncol = 1)
m.Pn.fit = matrix(nrow = 4, ncol = 3 * n.sites.p.ref)
m.exp.Pn = matrix(nrow = 4, ncol = 3 * n.sites.p.ref)
m.Pn.R2 = matrix(nrow = 4, ncol = 1)
m.Pn.MSE = matrix(nrow = 4, ncol = 1)
m.mean.theo.Pn.group = matrix(nrow = 4, ncol = 3 * n.sites.p.ref)
m.mean.exp.Pn = matrix(nrow = 4, ncol = 3 * n.sites.p.ref)
m.exp.Pn.sd = matrix(nrow = 4, ncol = 3 * n.sites.p.ref)
# Read betas.
all.betas <- list("strong.sel", "medium.sel", "weak.sel", "no.sel")
# Start a loop for each beta.
for (beta in all.betas)  {
### Experimental ###
analysis.fname.id <- paste(family, "_R0_", R0, "_beta_", beta, "_K.analysis_", K.analysis, sep = "")
m.exp.Pn = read.csv(file.path(out.dir, paste(analysis.fname.id, "_out_m.exp.Pn.csv", sep = "")))[, 1:100]
n.prot = nrow(m.exp.Pn)
mean.exp.Pn = colMeans(m.exp.Pn)
exp.Pn.sd = 2.63 * apply(m.exp.Pn, 2, sd, na.rm = T)/sqrt(n.prot-1)
m.mean.exp.Pn[as.vector(all.betas == beta), 1:length(mean.exp.Pn)] = mean.exp.Pn
m.exp.smooth.norm.dr.squarei = read.csv(file.path(out.dir, paste(analysis.fname.id, "_out_m.exp.smooth.norm.dr.squarei.csv", sep = "")))
exp.smooth.norm.MSDi = colMeans(m.exp.smooth.norm.dr.squarei, na.rm = T )
exp.smooth.norm.MSDi.sd = 2.63 * apply(m.exp.smooth.norm.dr.squarei, 2, sd, na.rm = T)/sqrt(n.prot-1)
### Theoretical ###
m.theo.Pn = read.csv(file.path(out.dir, paste(analysis.fname.id, "_out_m.theo.Pn.csv", sep = "")))[, 1:100]
m.theo.smooth.norm.dr.squarei = read.csv(file.path(out.dir, paste(analysis.fname.id, "_out_m.theo.smooth.norm.dr.squarei.csv", sep = "")))
theo.smooth.norm.MSDi = colMeans(m.theo.smooth.norm.dr.squarei, na.rm = T )
n.mut = nrow(m.theo.Pn)
fit = lm(exp.smooth.norm.MSDi ~ theo.smooth.norm.MSDi )
MSDi.fit = fitted.values(fit)
MSDi.R2 = cor(exp.smooth.norm.MSDi[!is.na(exp.smooth.norm.MSDi)], MSDi.fit) ^ 2
MSDi.MSE = mean((MSDi.fit - exp.smooth.norm.MSDi[!is.na(exp.smooth.norm.MSDi)]) ^ 2)
exp.smooth.norm.MSDi = exp.smooth.norm.MSDi[!is.na(exp.smooth.norm.MSDi)]
m.MSDi.fit[as.vector(all.betas == beta), ] = MSDi.fit
m.MSDi.R2[as.vector(all.betas == beta), ] = MSDi.R2
m.MSDi.MSE[as.vector(all.betas == beta), ] = MSDi.MSE
m.exp.MSDi[as.vector(all.betas == beta), ] = exp.smooth.norm.MSDi
m.exp.MSDi.sd[as.vector(all.betas == beta), ] = exp.smooth.norm.MSDi.sd[!is.na(exp.smooth.norm.MSDi.sd)]
### Pn ###
# Calculate groups, means and quantiles.
theo.Pn.group = CalculateGroupsMeansQuantiles(m.theo.Pn, n.mut.p, n.prot)
mean.theo.Pn.group = theo.Pn.group$mean.mean.group
m.mean.theo.Pn.group[as.vector(all.betas == beta), 1:length(mean.theo.Pn.group)] = mean.theo.Pn.group
Pn.fit = lm(mean.exp.Pn ~  mean.theo.Pn.group)
Pn.fit = fitted.values(Pn.fit)
Pn.R2 = cor(mean.exp.Pn, Pn.fit) ^ 2
Pn.MSE = mean((Pn.fit - mean.exp.Pn) ^ 2)
m.Pn.fit[as.vector(all.betas == beta), 1:(length(Pn.fit))] = Pn.fit
m.Pn.R2[as.vector(all.betas == beta), ] = Pn.R2
m.Pn.MSE[as.vector(all.betas == beta), ] = Pn.MSE
m.mean.exp.Pn[as.vector(all.betas == beta), 1:(length(mean.exp.Pn))] = mean.exp.Pn
m.exp.Pn.sd[as.vector(all.betas == beta), 1:(length(exp.Pn.sd))] = exp.Pn.sd
# Write pdb files for MSDi.
pdbs.fname <- file.path(data.dir, paste(family, "_coordinates.pdb", sep = ""))
pdb = ReadCA(pdbs.fname, as.character(chain.p.ref))
xyz.calpha = pdb$xyz.calpha
MSDi.fit.pdb <- vec2resno(as.vector(MSDi.fit), sort(rep(1:ncol(xyz.calpha),3)))
write.pdb(xyz = c(xyz.calpha), b = MSDi.fit.pdb, file = file.path(out.dir, paste(family, "_", p.ref, "_beta_", beta, ".pdb", sep = "")))
MSDi.exp.pdb <- vec2resno(as.vector(exp.smooth.norm.MSDi), sort(rep(1:ncol(xyz.calpha),3)))
write.pdb(xyz = c(xyz.calpha), b = MSDi.exp.pdb, file = file.path(out.dir, paste(family, "_", p.ref, "_exp", ".pdb", sep ="")))
}
# Chunk 3
layout(matrix(1:4, 2, 2, byrow = T))
MSDi.exp = m.exp.MSDi[1, ]
MSDi.theo = m.MSDi.fit[1, ]
MSDi.exp.sd = m.exp.MSDi.sd[1, ]
data.MSDi = data.frame("MSDi.exp" = MSDi.exp, "MSDi.theo" = MSDi.theo, "sites" = seq(1:length(MSDi.exp)), "MSDi.exp.sd" = MSDi.exp.sd)
ggplot(data = data.MSDi, aes(x = sites)) +
geom_point(aes(y = MSDi.exp, colour = "MSDi.exp")) +
geom_line(aes(y = MSDi.theo, colour = "MSDi.theo"), col = "black") +
ylab("MSDi strong selecion") +
geom_errorbar(aes(y = MSDi.exp, ymin = MSDi.exp - MSDi.exp.sd, ymax = MSDi.exp + MSDi.exp.sd), width = 0, col = "red")
MSDi.exp = m.exp.MSDi[2, ]
MSDi.theo = m.MSDi.fit[2, ]
MSDi.exp.sd = m.exp.MSDi.sd[2, ]
data.MSDi = data.frame("MSDi.exp" = MSDi.exp, "MSDi.theo" = MSDi.theo, "sites" = seq(1:length(MSDi.exp)), "MSDi.exp.sd" = MSDi.exp.sd)
ggplot(data = data.MSDi, aes(x = sites)) +
geom_point(aes(y = MSDi.exp, colour = "MSDi.exp")) +
geom_line(aes(y = MSDi.theo, colour = "MSDi.theo"), col = "black") +
ylab("MSDi medium selecion") +
geom_errorbar(aes(y = MSDi.exp, ymin = MSDi.exp - MSDi.exp.sd, ymax = MSDi.exp + MSDi.exp.sd), width = 0, col = "red")
MSDi.exp = m.exp.MSDi[3, ]
MSDi.theo = m.MSDi.fit[3, ]
MSDi.exp.sd = m.exp.MSDi.sd[3, ]
data.MSDi = data.frame("MSDi.exp" = MSDi.exp, "MSDi.theo" = MSDi.theo, "sites" = seq(1:length(MSDi.exp)), "MSDi.exp.sd" = MSDi.exp.sd)
ggplot(data = data.MSDi, aes(x = sites)) +
geom_point(aes(y = MSDi.exp, colour = "MSDi.exp")) +
geom_line(aes(y = MSDi.theo, colour = "MSDi.theo"), col = "black") +
ylab("MSDi weak selecion") +
geom_errorbar(aes(y = MSDi.exp, ymin = MSDi.exp - MSDi.exp.sd, ymax = MSDi.exp + MSDi.exp.sd), width = 0, col = "red")
MSDi.exp = m.exp.MSDi[4, ]
MSDi.theo = m.MSDi.fit[4, ]
MSDi.exp.sd = m.exp.MSDi.sd[4, ]
data.MSDi = data.frame("MSDi.exp" = MSDi.exp, "MSDi.theo" = MSDi.theo, "sites" = seq(1:length(MSDi.exp)), "MSDi.exp.sd" = MSDi.exp.sd)
ggplot(data = data.MSDi, aes(x = sites)) +
geom_point(aes(y = MSDi.exp, colour = "MSDi.exp")) +
geom_line(aes(y = MSDi.theo, colour = "MSDi.theo"), col = "black") +
ylab("MSDi no selecion") +
geom_errorbar(aes(y = MSDi.exp, ymin = MSDi.exp - MSDi.exp.sd, ymax = MSDi.exp + MSDi.exp.sd), width = 0, col = "red")
# Chunk 4
layout(matrix(1:4, 2, 2, byrow = T))
plot(m.MSDi.fit[1, ], m.exp.MSDi[1, ], xlab = "MSDi teorico", ylab = "MSDi experimental", main = "MSDi strong selection")
abline(0, 1)
legend("topleft", paste("R^2", round(m.MSDi.R2[1, ], digits = 2)), bty = "n", text.col = "red")
legend("bottomright", paste("MSE", signif(m.MSDi.MSE[1, ], digits = 2)), bty = "n", text.col = "red")
plot(m.MSDi.fit[2, ], m.exp.MSDi[2, ], xlab = "MSDi teorico", ylab = "MSDi experimental", main = "MSDi medium selection")
abline(0, 1)
legend("topleft", paste("R^2", round(m.MSDi.R2[2, ], digits = 2)), bty = "n", text.col = "red")
legend("bottomright", paste("MSE", signif(m.MSDi.MSE[2, ], digits = 2)), bty = "n", text.col = "red")
plot(m.MSDi.fit[3, ], m.exp.MSDi[3, ], xlab = "MSDi teorico", ylab = "MSDi experimental", main = "MSDi weak selection")
abline(0, 1)
legend("topleft", paste("R^2", round(m.MSDi.R2[3, ], digits = 2)), bty = "n", text.col = "red")
legend("bottomright", paste("MSE", signif(m.MSDi.MSE[3, ], digits = 2)), bty = "n", text.col = "red")
plot(m.MSDi.fit[4, ], m.exp.MSDi[4, ], xlab = "MSDi teorico", ylab = "MSDi experimental", main = "MSDi no selection")
abline(0, 1)
legend("topleft", paste("R^2", round(m.MSDi.R2[4, ], digits = 2)), bty = "n", text.col = "red")
legend("bottomright", paste("MSE", signif(m.MSDi.MSE[4, ], digits = 2)), bty = "n", text.col = "red")
# Chunk 5
layout(matrix(1:4, 2, 2, byrow = T))
Pn.exp = m.mean.exp.Pn[1, 1:100]
Pn.theo = m.mean.theo.Pn.group[1, 1:100]
Pn.exp.sd = m.exp.Pn.sd[1, 1:100]
data.Pn = data.frame("Pn.exp" = Pn.exp, "Pn.theo" = Pn.theo, "modes" = seq(1:length(Pn.exp)), "Pn.exp.sd" = Pn.exp.sd)
ggplot(data = data.Pn, aes(x = modes)) +
geom_point(aes(y = Pn.exp, colour = "Pn.exp")) +
geom_line(aes(y = Pn.theo, colour = "Pn.theo"), col = "black") +
ylab("Pn strong selecion") +
geom_errorbar(aes(y = Pn.exp, ymin = Pn.exp - Pn.exp.sd, ymax = Pn.exp + Pn.exp.sd), width = 0, col = "red")
Pn.exp = m.mean.exp.Pn[2, 1:100]
Pn.theo = m.mean.theo.Pn.group[2, 1:100]
Pn.exp.sd = m.exp.Pn.sd[2, 1:100]
data.Pn = data.frame("Pn.exp" = Pn.exp, "Pn.theo" = Pn.theo, "modes" = seq(1:length(Pn.exp)), "Pn.exp.sd" = Pn.exp.sd)
ggplot(data = data.Pn, aes(x = modes)) +
geom_point(aes(y = Pn.exp, colour = "Pn.exp")) +
geom_line(aes(y = Pn.theo, colour = "Pn.theo"), col = "black") +
ylab("Pn medium selecion") +
geom_errorbar(aes(y = Pn.exp, ymin = Pn.exp - Pn.exp.sd, ymax = Pn.exp + Pn.exp.sd), width = 0, col = "red")
Pn.exp = m.mean.exp.Pn[3, 1:100]
Pn.theo = m.mean.theo.Pn.group[3, 1:100]
Pn.exp.sd = m.exp.Pn.sd[3, 1:100]
data.Pn = data.frame("Pn.exp" = Pn.exp, "Pn.theo" = Pn.theo, "modes" = seq(1:length(Pn.exp)), "Pn.exp.sd" = Pn.exp.sd)
ggplot(data = data.Pn, aes(x = modes)) +
geom_point(aes(y = Pn.exp, colour = "Pn.exp")) +
geom_line(aes(y = Pn.theo, colour = "Pn.theo"), col = "black") +
ylab("Pn weak selecion") +
geom_errorbar(aes(y = Pn.exp, ymin = Pn.exp - Pn.exp.sd, ymax = Pn.exp + Pn.exp.sd), width = 0, col = "red")
Pn.exp = m.mean.exp.Pn[4, 1:100]
Pn.theo = m.mean.theo.Pn.group[4, 1:100]
Pn.exp.sd = m.exp.Pn.sd[4, 1:100]
data.Pn = data.frame("Pn.exp" = Pn.exp, "Pn.theo" = Pn.theo, "modes" = seq(1:length(Pn.exp)), "Pn.exp.sd" = Pn.exp.sd)
ggplot(data = data.Pn, aes(x = modes)) +
geom_point(aes(y = Pn.exp, colour = "Pn.exp")) +
geom_line(aes(y = Pn.theo, colour = "Pn.theo"), col = "black") +
ylab("Pn no selecion") +
geom_errorbar(aes(y = Pn.exp, ymin = Pn.exp - Pn.exp.sd, ymax = Pn.exp + Pn.exp.sd), width = 0, col = "red")
# Chunk 6
layout(matrix(1:4, 2, 2, byrow = T))
plot(m.mean.theo.Pn.group[1, ], m.mean.exp.Pn[1, ], xlab = "<<Pn>> teorico", ylab = "<Pn> experimental", main = "Pn strong selection")
abline(0, 1)
legend("topleft", paste("R^2", round(m.Pn.R2[1, ], digits = 2)), bty = "n", text.col = "red")
legend("bottomright", paste("MSE", signif(m.Pn.MSE[1, ], digits = 2)), bty = "n", text.col = "red")
plot(m.mean.theo.Pn.group[2, ], m.mean.exp.Pn[2, ], xlab = "<<Pn>> teorico", ylab = "<Pn> experimental", main = "Pn medium selection")
abline(0, 1)
legend("topleft", paste("R^2", round(m.Pn.R2[2, ], digits = 2)), bty = "n", text.col = "red")
legend("bottomright", paste("MSE", signif(m.Pn.MSE[2, ], digits = 2)), bty = "n", text.col = "red")
plot(m.mean.theo.Pn.group[3, ], m.mean.exp.Pn[3, ], xlab = "<<Pn>> teorico", ylab = "<Pn> experimental", main = "Pn weak selection")
abline(0, 1)
legend("topleft", paste("R^2", round(m.Pn.R2[3, ], digits = 2)), bty = "n", text.col = "red")
legend("bottomright", paste("MSE", signif(m.Pn.MSE[3, ], digits = 2)), bty = "n", text.col = "red")
plot(m.mean.theo.Pn.group[4, ], m.mean.exp.Pn[4, ], xlab = "<<Pn>> teorico", ylab = "<Pn> experimental", main = "Pn no selection")
abline(0, 1)
legend("topleft", paste("R^2", round(m.Pn.R2[4, ], digits = 2)), bty = "n", text.col = "red")
legend("bottomright", paste("MSE", signif(m.Pn.MSE[4, ], digits = 2)), bty = "n", text.col = "red")
exp.smooth.norm.MSDi.sd
exp.smooth.norm.MSDi.sd
exp.smooth.norm.MSDi.sd[!is.na(exp.smooth.norm.MSDi.sd)]
exp.smooth.norm.MSDi.sd
# Load packages.
library(bio3d)
# Source functions.
source("FUNCTIONS/CalculateGroupsMeansQuantiles.R")
# Set directories.
data.dir <- "DATA"
out.dir <- "OUT"
# p.ref.
n.sites.p.ref = read.csv(file.path(out.dir, paste(family, "_out_m.n.sites.p.ref.csv", sep = "")))$V1[1]
# Create matrices to save data.
m.MSDi.fit = matrix(nrow = 4, ncol = n.sites.p.ref)
m.exp.MSDi = matrix(nrow = 4, ncol = n.sites.p.ref)
m.exp.MSDi.sd = matrix(nrow = 4, ncol = n.sites.p.ref)
m.MSDi.R2 = matrix(nrow = 4, ncol = 1)
m.MSDi.MSE = matrix(nrow = 4, ncol = 1)
m.Pn.fit = matrix(nrow = 4, ncol = 3 * n.sites.p.ref)
m.exp.Pn = matrix(nrow = 4, ncol = 3 * n.sites.p.ref)
m.Pn.R2 = matrix(nrow = 4, ncol = 1)
m.Pn.MSE = matrix(nrow = 4, ncol = 1)
m.mean.theo.Pn.group = matrix(nrow = 4, ncol = 3 * n.sites.p.ref)
m.mean.exp.Pn = matrix(nrow = 4, ncol = 3 * n.sites.p.ref)
m.exp.Pn.sd = matrix(nrow = 4, ncol = 3 * n.sites.p.ref)
# Read betas.
all.betas <- list("strong.sel", "medium.sel", "weak.sel", "no.sel")
# Start a loop for each beta.
for (beta in all.betas)  {
### Experimental ###
analysis.fname.id <- paste(family, "_R0_", R0, "_beta_", beta, "_K.analysis_", K.analysis, sep = "")
m.exp.Pn = read.csv(file.path(out.dir, paste(analysis.fname.id, "_out_m.exp.Pn.csv", sep = "")))[, 1:100]
n.prot = nrow(m.exp.Pn)
mean.exp.Pn = colMeans(m.exp.Pn)
exp.Pn.sd = 2.63 * apply(m.exp.Pn, 2, sd, na.rm = T)/sqrt(n.prot-1)
m.mean.exp.Pn[as.vector(all.betas == beta), 1:length(mean.exp.Pn)] = mean.exp.Pn
m.exp.smooth.norm.dr.squarei = read.csv(file.path(out.dir, paste(analysis.fname.id, "_out_m.exp.smooth.norm.dr.squarei.csv", sep = "")))
exp.smooth.norm.MSDi = colMeans(m.exp.smooth.norm.dr.squarei, na.rm = T )
exp.smooth.norm.MSDi.sd = 2.63 * apply(m.exp.smooth.norm.dr.squarei, 2, sd, na.rm = T)/sqrt(n.prot-1)
### Theoretical ###
m.theo.Pn = read.csv(file.path(out.dir, paste(analysis.fname.id, "_out_m.theo.Pn.csv", sep = "")))[, 1:100]
m.theo.smooth.norm.dr.squarei = read.csv(file.path(out.dir, paste(analysis.fname.id, "_out_m.theo.smooth.norm.dr.squarei.csv", sep = "")))
theo.smooth.norm.MSDi = colMeans(m.theo.smooth.norm.dr.squarei, na.rm = T )
n.mut = nrow(m.theo.Pn)
fit = lm(exp.smooth.norm.MSDi ~ theo.smooth.norm.MSDi )
MSDi.fit = fitted.values(fit)
MSDi.R2 = cor(exp.smooth.norm.MSDi[!is.na(exp.smooth.norm.MSDi)], MSDi.fit) ^ 2
MSDi.MSE = mean((MSDi.fit - exp.smooth.norm.MSDi[!is.na(exp.smooth.norm.MSDi)]) ^ 2)
exp.smooth.norm.MSDi = exp.smooth.norm.MSDi[!is.na(exp.smooth.norm.MSDi)]
m.MSDi.fit[as.vector(all.betas == beta), ] = MSDi.fit
m.MSDi.R2[as.vector(all.betas == beta), ] = MSDi.R2
m.MSDi.MSE[as.vector(all.betas == beta), ] = MSDi.MSE
m.exp.MSDi[as.vector(all.betas == beta), ] = exp.smooth.norm.MSDi
m.exp.MSDi.sd[as.vector(all.betas == beta), ] = exp.smooth.norm.MSDi.sd[!is.na(exp.smooth.norm.MSDi.sd)]
### Pn ###
# Calculate groups, means and quantiles.
theo.Pn.group = CalculateGroupsMeansQuantiles(m.theo.Pn, n.mut.p, n.prot)
mean.theo.Pn.group = theo.Pn.group$mean.mean.group
m.mean.theo.Pn.group[as.vector(all.betas == beta), 1:length(mean.theo.Pn.group)] = mean.theo.Pn.group
Pn.fit = lm(mean.exp.Pn ~  mean.theo.Pn.group)
Pn.fit = fitted.values(Pn.fit)
Pn.R2 = cor(mean.exp.Pn, Pn.fit) ^ 2
Pn.MSE = mean((Pn.fit - mean.exp.Pn) ^ 2)
m.Pn.fit[as.vector(all.betas == beta), 1:(length(Pn.fit))] = Pn.fit
m.Pn.R2[as.vector(all.betas == beta), ] = Pn.R2
m.Pn.MSE[as.vector(all.betas == beta), ] = Pn.MSE
m.mean.exp.Pn[as.vector(all.betas == beta), 1:(length(mean.exp.Pn))] = mean.exp.Pn
m.exp.Pn.sd[as.vector(all.betas == beta), 1:(length(exp.Pn.sd))] = exp.Pn.sd
# Write pdb files for MSDi.
pdbs.fname <- file.path(data.dir, paste(family, "_coordinates.pdb", sep = ""))
pdb = ReadCA(pdbs.fname, as.character(chain.p.ref))
xyz.calpha = pdb$xyz.calpha
MSDi.fit.pdb <- vec2resno(as.vector(MSDi.fit), sort(rep(1:ncol(xyz.calpha),3)))
write.pdb(xyz = c(xyz.calpha), b = MSDi.fit.pdb, file = file.path(out.dir, paste(family, "_", p.ref, "_beta_", beta, ".pdb", sep = "")))
MSDi.exp.pdb <- vec2resno(as.vector(exp.smooth.norm.MSDi), sort(rep(1:ncol(xyz.calpha),3)))
write.pdb(xyz = c(xyz.calpha), b = MSDi.exp.pdb, file = file.path(out.dir, paste(family, "_", p.ref, "_exp", ".pdb", sep ="")))
}
m.exp.MSDi.sd
as.vector(all.betas == beta)
m.exp.MSDi.sd[as.vector(all.betas == beta), ]
exp.smooth.norm.MSDi.sd[!is.na(exp.smooth.norm.MSDi.sd)]
m.exp.MSDi.sd[as.vector(all.betas == beta), ] = exp.smooth.norm.MSDi.sd[!is.na(exp.smooth.norm.MSDi.sd)]
exp.smooth.norm.MSDi.sd[!is.na(exp.smooth.norm.MSDi.sd)]
length(exp.smooth.norm.MSDi.sd[!is.na(exp.smooth.norm.MSDi.sd)])
exp.smooth.norm.MSDi.sd
exp.smooth.norm.MSDi
exp.smooth.norm.MSDi
exp.smooth.norm.MSDi.sd
m.exp.smooth.norm.dr.squarei
P
a
# Load packages.
library(knitr)
library(markdown)
# Read input.
input.fname <- file.path("input_MainMultipleReport.csv")
input <- read.csv(input.fname)
# Satart a loop for each family.
for (a in (1:nrow(input))) {
print(a)
family <- as.character(input$family)[a]
p.ref <- as.character(input$p.ref)[a]
chain.p.ref = input$chain.p.ref[a]
n.mut.p = input$n.mut.p[a]
R0 = input$R0[a]
K.analysis = input$K.analysis[a]
# Generate a report.
rmarkdown::render('MultipleReportAllBetas.Rmd',
output_file =  paste("report_", family, "_R0_", R0, "_K.analysis_", K.analysis, ".html", sep = ''))
}
# Load packages.
library(knitr)
library(markdown)
# Read input.
input.fname <- file.path("input_MainMultipleReport.csv")
input <- read.csv(input.fname)
# Satart a loop for each family.
for (a in (1:nrow(input))) {
print(a)
family <- as.character(input$family)[a]
p.ref <- as.character(input$p.ref)[a]
chain.p.ref = input$chain.p.ref[a]
n.mut.p = input$n.mut.p[a]
R0 = input$R0[a]
K.analysis = input$K.analysis[a]
# Generate a report.
rmarkdown::render('MultipleReportAllBetas.Rmd',
output_file =  paste("report_", family, "_R0_", R0, "_K.analysis_", K.analysis, ".html", sep = ''))
}
help("geom_errorbar")
